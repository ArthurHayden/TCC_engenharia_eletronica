# -*- coding: utf-8 -*-
"""rede_3_4_classes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fVFtJ6Q_Ah5beobb9HdczXv2le6XLqhm
"""

from keras.models import Sequential, load_model
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
from tensorflow.keras import layers
from tensorflow.keras.utils import load_img, img_to_array
from keras.preprocessing import image
import os
import matplotlib.pyplot as plt
import pickle
import tensorflow as tf
import pandas as pd
from PIL import Image
from keras.layers import Input
from keras.optimizers import SGD
from keras.callbacks import CSVLogger
from tensorflow.keras import models
from google.colab import drive
try:
    drive.mount('/content/gdrive')
except:
    pass
os.chdir('/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/historicos/rede_3')

#DADOS DO PROGRAMA
#CLASSES : 4
#BANCO : SARTAJ
#CHECKPOINTS: SIM
#HISTORICO LOG: SIM
#GERADOR DE DADOS: SIM
#MATRIZ CONFUSÃO: SIM
#AUMENTO DE DADOS : SIM
#AUTOR: ARTHUR CAMPELO (ArthurHayden )
def plot_training_history(history):
    # Training history visualization

    plt.plot(history['accuracy'], label = 'Training', linewidth = 1.2)
    plt.plot(history['val_accuracy'], label = 'Validation', linewidth = 1.2)
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend(loc="upper left")
    plt.show()
    plt.plot(history['loss'], label = 'Training', linewidth = 1.2)
    plt.plot(history['val_loss'], label = 'Validation', linewidth = 1.2)
    plt.xlabel('Epoch')
    plt.ylabel('Loss function')
    plt.legend(loc="upper left")
    plt.show()



def reduction_confusion_matrix(conf_matrix, y_true, class_counts, data_generator, file_object ):
    metrics = {}
    class_names = list(data_generator.class_indices.keys())  # Use as classes do ImageDataGenerator
    class_indices = list(data_generator.class_indices.values())  # Obtenha os índices das classes
    num_classes = len(np.unique(y_true))  # Número de classes
    precision = np.zeros((4))
    recall = np.zeros((4))
    f1_score = np.zeros((4))
    accuracy =np.zeros((4))
    total_images = sum(class_counts.values())
    print(f'Total de Imagens: {total_images}\n')
    df_metrics = pd.DataFrame(index=range(num_classes), columns=['precision', 'recall', 'f1_score', 'accuracy'])
    for i, class_name in enumerate(class_names):  # Iterar sobre os nomes das classes e seus índices
        # Criando matriz reduzida 2x2
        reduced_matrix = np.zeros((2, 2))


        # Preenchendo a diagonal com verdadeiros positivos e verdadeiros negativos
        TP = conf_matrix[i, i]
        TN = np.sum(conf_matrix) - np.sum(conf_matrix[i, :]) - np.sum(conf_matrix[:, i]) + TP

        reduced_matrix[0, 0] = TP
        reduced_matrix[1, 1] = TN

        # Preenchendo o resto com falsos positivos e falsos negativos
        FP = np.sum(conf_matrix[:, i]) - TP
        FN = np.sum(conf_matrix[i, :]) - TP

        reduced_matrix[0, 1] = FP
        reduced_matrix[1, 0] = FN

        # Calculando as métricas a partir da matriz reduzida
        precision[i] = TP / (TP + FP)
        recall[i] =  TP / (TP + FN)
        f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i])
        accuracy[i] = (TP + TN) / (TP+TN+FP+FN)

        # Armazenando as métricas para cada classe
        metrics[i] = {
            'precision': precision[i],
            'recall': recall[i],
            'f1_score': f1_score[i],
            'accuracy': accuracy[i],
            'true_positive': TP,
            'false_positive': FP,
            'false_negative': FN,
            'true_negative': TN
        }
        df_metrics.loc[i] = [precision[i], recall[i], f1_score[i], accuracy[i]]
        # Plotando a matriz de confusão reduzida
        print()

        print(f'\nClasse {class_indices[i]}: {class_name} (Imagens: {class_counts.get(class_name, 0)})')
        print('imagens de outras classes', total_images - class_counts.get(class_name, 0))
        print(f'Classe Predominante: {class_names[np.argmax(conf_matrix[i])]}')  # Obter a classe predominante usando argmax
        print("Matriz de Confusão Reduzida (0 = classe atual, 1 = outras classes):")
        print(pd.DataFrame(reduced_matrix))

        output_string = f"\nClasse {i}: {class_name} (Imagens: {class_counts.get(class_name, 0)})\n"
        output_string += f"imagens de outras classes: {total_images - class_counts.get(class_name, 0)}\n"
        output_string += f"Classe Predominante: {class_names[np.argmax(conf_matrix[i])]}\n"
        output_string += "Matriz de Confusão Reduzida (0 = classe atual, 1 = outras classes):\n"
        output_string += pd.DataFrame(reduced_matrix).to_markdown(numalign='left', stralign='left') + "\n\n"
        print()
        if file_object:  # Escreve no arquivo se file_object for fornecido
            file_object.write(output_string)
            file_object.write("\n")






    # Calculando e imprimindo médias das métricas

    print(70*'-')
    df_metrics.loc['Média'] = df_metrics.mean()

    # Imprimindo o DataFrame em formato de tabela
    print(df_metrics.to_markdown(numalign='left', stralign='left'))
    print(70*'-')
    if file_object:
        file_object.write("\nTabela de Métricas:\n")
        metrics_df = pd.DataFrame(metrics).transpose()
        metrics_df.loc['Média'] = metrics_df.mean()
        file_object.write(metrics_df.to_markdown(numalign='left', stralign='left'))

    return metrics



"""def confusion_matrix(data_generator, model):

    Calcula a matriz de confusão

    Args:
        data_generator: Um objeto ImageDataGenerator contendo os dados e rótulos.
        model: O modelo de classificação treinado.

    Returns:
        numpy.ndarray: A matriz de confusão.


    y_true = []
    y_pred = []

    # Itera sobre todos os lotes do gerador de dados
    print("tamanho dos dados",len(data_generator))
    for _ in range(len(data_generator)):
        x_batch, y_batch = data_generator.next()
        y_true.extend(np.argmax(y_batch, axis=1))  # Extrai os rótulos verdadeiros
        y_pred_prob = model.predict(x_batch)
        y_pred.extend(np.argmax(y_pred_prob, axis=1))  # Extrai as previsões
    print("tamanho do x batch",len(x_batch))
    print("tamanho do y batch",len(y_batch))
    print("tamanho do y true",len(y_true))
    print("tamanho do y pred",len(y_pred))
    # Calcula a matriz de confusão
    num_classes = len(data_generator.class_indices)
    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)
    for i in range(len(y_true)):
        conf_matrix[y_true[i], y_pred[i]] += 1

    return conf_matrix, y_true
"""


def confusion_matrix(image_paths, model, target_size):
    """
    Calcula a matriz de confusão para imagens em uma lista de caminhos,
    usando o nome da pasta como rótulo da classe.

    Args:
        image_paths (list): Uma lista de caminhos para as imagens.
        model: O modelo de classificação treinado.
        target_size (tuple): O tamanho desejado para as imagens (largura, altura).

    Returns:
        numpy.ndarray: A matriz de confusão.
        numpy.ndarray: Os rótulos verdadeiros.
    """

    y_true = []
    y_pred = []
    class_names = set()  # Conjunto para armazenar os nomes das classes únicas
    class_counts = {}

    for image_path in image_paths:
        # 1. Carrega a imagem e redimensiona
        img = load_img(image_path, target_size=target_size, color_mode="grayscale")
        img_array = img_to_array(img) / 255.0  # Normaliza
        img_array = np.expand_dims(img_array, axis=0)  # Adiciona dimensão do lote

        # 2. Obtém o rótulo verdadeiro a partir do nome da pasta
        class_name = os.path.basename(os.path.dirname(image_path))
        class_names.add(class_name)  # Adiciona o nome da classe ao conjunto

        class_counts[class_name] = class_counts.get(class_name, 0) + 1  # Incrementa a contagem
        y_true.append(class_name)  # Armazena o nome da classe como rótulo verdadeiro

        # 3. Realiza a previsão
        y_pred_prob = model.predict(img_array)
        y_pred.append(np.argmax(y_pred_prob, axis=1)[0])  # Índice da classe prevista

    # 4. Calcula a matriz de confusão
    class_names = sorted(list(class_names))  # Ordena os nomes das classes
    num_classes = len(class_names)
    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)

    # Mapeia os nomes das classes para índices
    class_to_index = {class_name: i for i, class_name in enumerate(class_names)}

    for i in range(len(y_true)):
        true_index = class_to_index[y_true[i]]
        conf_matrix[true_index, y_pred[i]] += 1

    return conf_matrix, y_true, class_counts

# Cria o modelo caso não exista
#learning_rate = 0.05 # taxa de apredizagem
#optimizer = SGD(learning_rate=learning_rate)
target_size=(128 , 128)
input_shape = (target_size[0], target_size[1], 1)

input_layer = Input(shape=input_shape)

# Criar o modelo Sequential
c = models.Sequential([
    input_layer,  # Usar o objeto Input como primeira camada
    layers.Conv2D(filters=32, kernel_size=[3, 3], activation='relu'),

    layers.MaxPooling2D([2, 2]),
    layers.Conv2D(filters=64, kernel_size=[3, 3], activation='relu'),

    layers.MaxPooling2D([2, 2]),
    layers.Conv2D(filters=128, kernel_size=[3, 3], activation='relu'),

    layers.MaxPooling2D([2, 2]),
    Dropout(0.2),
    layers.Flatten(),
    layers.Dense(4, activation='softmax')
])


c.summary()
c.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
# optimizer='adam'
# loss='binary_crossentropy' melhor para 2 classes

file_treinamento ='/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/sartaj_dataset/Training'
file_validacao ='/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/sartaj_dataset/Validation'
file_teste ='/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/sartaj_dataset/Testing'
#file_treinamento ='/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/sartaj_dataset_augmentation/2_X_Training_augmentation'
#'/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/sartaj_dataset/Training'
#file_new_train = '/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/sartaj_dataset_bases_tamanho_igual/Training'
#file_new_val = '/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/sartaj_dataset_bases_tamanho_igual/Validation'
#file_new_test = '/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/sartaj_dataset_bases_tamanho_igual/Testing'
# SEPARAÇÃO DO BANCO DE DADOS
gerador_treinamento = ImageDataGenerator(rescale=1./255,
    rotation_range=20,
    horizontal_flip=True,
    vertical_flip=True,
    shear_range=0.05,
    zoom_range=0.1,
    )

gerador_validacao = ImageDataGenerator(rescale=1./255)
batch_size = 128
banco_treinamento = gerador_treinamento.flow_from_directory(file_treinamento,
                                                               target_size=target_size,
                                                               color_mode='grayscale',
                                                               batch_size=batch_size,
                                                               class_mode='categorical'
                                                               )

banco_validacao = gerador_validacao.flow_from_directory(file_validacao,
                                                               target_size=target_size,
                                                               color_mode='grayscale',
                                                               batch_size=batch_size,
                                                               class_mode='categorical'
                                                              )

# GERADOR DE TESTE

gerador_teste = ImageDataGenerator(rescale=1./255)


banco_teste = gerador_teste.flow_from_directory(file_teste,
                                                   target_size=target_size,
                                                   color_mode = 'grayscale',
                                                   batch_size=batch_size,
                                                   class_mode='categorical',
                                                   shuffle=False
                                                  )



def get_latest_test_number(base_dir):
    test_dirs = [d for d in os.listdir(base_dir) if d.startswith("teste_") and os.path.isdir(os.path.join(base_dir, d))]
    if test_dirs:
        latest_test_number = max([int(d.split("_")[1]) for d in test_dirs])
    else:
        latest_test_number = 0
    return latest_test_number

# ... (restante do seu código até antes da linha "trained_modelo=...")

print("Deseja fazer um novo treinamento (1) ou rever um teste (2)?")
op = input()

base_dir = '/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes/historicos/rede_3'

if op == "1":
    latest_test_number = get_latest_test_number(base_dir)
    new_test_number = latest_test_number + 1
    test_dir = os.path.join(base_dir, f"teste_{new_test_number}")
    os.makedirs(test_dir, exist_ok=True)  # Cria o diretório se não existir
    os.chdir(test_dir)  # Muda para o novo diretório
    print(f"Novo teste criado em: {test_dir}")

elif op == "2":
    test_dirs = [d for d in os.listdir(base_dir) if d.startswith("teste_") and os.path.isdir(os.path.join(base_dir, d))]
    if test_dirs:
        print("Testes encontrados:")
        for i, test_dir in enumerate(test_dirs):
            print(f"{i+1}. {test_dir}")
        escolha = int(input("Escolha o número do teste que deseja visualizar: ")) - 1
        selected_test_dir = test_dirs[escolha]
        os.chdir(os.path.join(base_dir, selected_test_dir))
        print(f"Visualizando o teste {selected_test_dir}")

    else:
        print("Nenhum teste encontrado.")
else:
    print("Opção inválida.")

trained_modelo= "rede_3_modelo_classificador_MRI.h5"
training_history_filename = 'rede_3_modelo_classificador_MRI_history'
# Verifica se o modelo já existe
if os.path.exists(trained_modelo):
    c = load_model(trained_modelo)
    c.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    # Carregar o histórico de treinamento
    #Se o arquivo do modelo existe, ele é carregado usando load_model,
    #que restaura tanto a arquitetura quanto os pesos do modelo

    history = pickle.load(open(training_history_filename, "rb"))
    plot_training_history(history)
    df = pd.read_csv('_rede_3_my_log.csv')
    history_dict = df.to_dict('list')
    print("GRAFICO COM O ARQUIVO MY LOG ")
    plot_training_history(history_dict)

else:

    # CASO A REDE NAO TENHA SIDO CRIADA
    #Número de lotes (batches) de dados de treinamento que o modelo processará em cada época.
    #steps_per_epoch = (Número total de amostras de treinamento) / batch_size - 1664 / 32 = 52
    #validation_steps = (Número total de amostras de validação) / batch_size - 224 / 32 = 7

    # ----| Checkpoints and Training |--{{{
    checkpoint_dir = './checkpoints_rede_3'
    if not os.path.isdir(checkpoint_dir):
        os.makedirs(checkpoint_dir)


    def get_latest_checkpoint(checkpoint_dir):
      checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith("ckpt_") and f.endswith(".weights.h5")]
      if checkpoint_files:
        # Filtra apenas os arquivos .index (que contêm o número da época)
        latest_checkpoint = max(checkpoint_files, key=lambda f: int(f.split("_")[1].split(".")[0]))
        # Retorna o nome base do arquivo (sem a extensão .index)
        return latest_checkpoint
      else:
        return None
    latest_checkpoint = get_latest_checkpoint(checkpoint_dir)
    print("o ultimo checkpoint",latest_checkpoint)

    if latest_checkpoint:
        c.load_weights(os.path.join(checkpoint_dir, latest_checkpoint))
        initial_epoch = int(latest_checkpoint.split("_")[1].split(".")[0]) # Extrai o número da época
        print(f"Retomando o treinamento da época {initial_epoch}")
    else:
        print("Iniciando um novo treinamento")
        initial_epoch = 0


    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
          filepath=os.path.join(checkpoint_dir, "ckpt_{epoch}.weights.h5"),
          save_weights_only=True,
    )
    num_treinamento=len(banco_treinamento)
    num_validacao=len(banco_validacao)
    print(num_treinamento , num_validacao)
    log_csv = CSVLogger('_rede_3_my_log.csv', separator=',', append=True)
    print("Amostras de treinamento:", len(banco_treinamento.filepaths))
    print("Amostras de validação:", len(banco_validacao.filepaths))

    callback_list=[checkpoint_callback, log_csv]
    history=c.fit(
        banco_treinamento,
        epochs = 300,
        validation_data= banco_validacao,
        verbose = 2,
        callbacks = callback_list,
        initial_epoch = initial_epoch
    )
    #steps_per_epoch= num_treinamento // 32,
    #validation_steps= num_validacao // 32,
    # Salva o modelo após o treinamento

    #plot_training_history: Uma função que você deve ter definido em outra parte
    #do seu código, que toma o dicionário history.history como argumento.
    #Este dicionário contém os valores da perda e das métricas que foram
    #calculadas no final de cada época para o conjunto de treinamento e validação.
    #Esta função visualiza esses valores para ajudar a entender como o modelo está
    #aprendendo e como está seu desempenho ao longo do tempo.
    plot_training_history(history.history)
    df = pd.read_csv('_rede_3_my_log.csv')
    history_dict = df.to_dict('list')
    print("GRAFICO COM O ARQUIVO MY LOG ")
    plot_training_history(history_dict)
    c.save(trained_modelo, include_optimizer=True)
    with open(training_history_filename, 'wb') as file_pi:
            pickle.dump(history.history, file_pi)
# TREINAMENTO/////////////////////////////////////////////////////////////////////////////////////////////////////////

os.chdir('/content/gdrive/MyDrive/teste_acesso_colab_drive/IA_MRI_4_classes')

folder_name = "metricas_matriz_confusao"
os.makedirs(folder_name, exist_ok=True)
#test_number = input("Qual é o número deste teste? ")
test_number = 55
filename = os.path.join(folder_name, f"teste_{test_number}_metricas_matriz.txt")
print("Deseja ver um arquivo já gravado? (sim/não)")
#res2 = input().lower()
res2="nao"
if res2 == "sim":
    # Listar arquivos TXT no diretório
    arquivos_txt = [f for f in os.listdir(folder_name) if f.endswith('.txt')]

    if arquivos_txt:
        print("Arquivos TXT encontrados:")
        for i, arquivo in enumerate(arquivos_txt):
            print(f"{i+1}. {arquivo}")

        # Perguntar qual arquivo abrir
        while True:
            try:
                escolha = int(input("Escolha o número do arquivo que deseja abrir: "))
                if 1 <= escolha <= len(arquivos_txt):
                    break
                else:
                    print("Número inválido. Tente novamente.")
            except ValueError:
                print("Entrada inválida. Digite um número.")

        filename = os.path.join(folder_name, arquivos_txt[escolha - 1])

        # Abrir e exibir o conteúdo do arquivo
        with open(filename, 'r') as f:
            print(f.read())
    else:
        print("Nenhum arquivo TXT encontrado no diretório.")

# TREINAMENTO/////////////////////////////////////////////////////////////////////////////////////////////////////////
print("deseja calcular matriz confusão conjunto de treinamento e métricas?")
#res = input()
res="sim"
if res.lower() == "sim":

  banco_treinamento.reset()
  ListOfFiles = []
  class_count = {}
  for (dirpath, dirnames, filenames) in os.walk(file_treinamento):
        ListOfFiles += [os.path.join(dirpath, file) for file in filenames]
  conf_matrix, y_true,class_count = confusion_matrix(ListOfFiles, c,target_size)
  print("tamanho dos rotulos", len(y_true))

  print()
  print("Matriz de Confusão treinamento simples:")
  for row in conf_matrix:
    for val in row:
      print(f"{val:4d}", end="")  # 4 espaços
    print()


  print()
  print("Matriz de Confusão: PANDAS")


  print("Matriz de Confusão: PANDAS")
  with open(filename, 'a') as f:
    f.write("\n Matriz de Confusão TREINAMENTO :\n")
    print(pd.DataFrame(conf_matrix))
    f.write(pd.DataFrame(conf_matrix).to_markdown(numalign='left', stralign='left'))
    reduction_confusion_matrix(conf_matrix, y_true,class_count, banco_treinamento, f)
#TESTE ///////////////////////////////////////////////////////////////////////////////////////////
print("Deseja calcular matriz confusão conjunto de teste e métricas?")
#res = input()
res="sim"
if res.lower() == "sim":

  ListOfFiles2 = []
  class_count2 = {}
  for (dirpath, dirnames, filenames) in os.walk(file_teste):
        ListOfFiles2 += [os.path.join(dirpath, file) for file in filenames]
  banco_teste.reset()
  conf_matrix, y_true,class_count2 = confusion_matrix(ListOfFiles2, c, target_size)
  print()


  print("Matriz de Confusão teste simples:")
  for row in conf_matrix:
    for val in row:
      print(f"{val:4d}", end="")  # 4 espaços
    print()


  print()
  print("Matriz de Confusão: PANDAS")
  with open(filename, 'a') as f:
    f.write("\n Matriz de Confusão TESTE :\n")
    print(pd.DataFrame(conf_matrix))
    f.write(pd.DataFrame(conf_matrix).to_markdown(numalign='left', stralign='left'))
    reduction_confusion_matrix(conf_matrix, y_true,class_count2, banco_teste, f)
# VALIDAÇÃO ///////////////////////////////////////////////////////////////////////////////////////
print("Deseja calcular matriz confusão conjunto de validação e métricas?")
#res=input()
res="sim"
if res.lower() == "sim":
  ListOfFiles3 = []
  class_count3 = {}
  for (dirpath, dirnames, filenames) in os.walk(file_validacao):
        ListOfFiles3 += [os.path.join(dirpath, file) for file in filenames]
  banco_teste.reset()
  conf_matrix, y_true,class_count3 = confusion_matrix(ListOfFiles3, c,target_size)
  print()
  print("Matriz de Confusão validação simples:")
  for row in conf_matrix:
    for val in row:
      print(f"{val:4d}", end="")  # 4 espaços
    print()


  print()



  print("Matriz de Confusão: PANDAS")
  with open(filename, 'a') as f:
    f.write("\n Matriz de Confusão VALIDAÇÃO :\n")
    print(pd.DataFrame(conf_matrix))
    f.write(pd.DataFrame(conf_matrix).to_markdown(numalign='left', stralign='left'))
    reduction_confusion_matrix(conf_matrix, y_true,class_count3, banco_validacao, f)


print("Deseja testar uma imagem? (sim/nao)")
#res = input()
res="sim"
if res.lower() == "sim":
    # Classes de cada pasta
    class_names = os.listdir(file_teste)
    print("Classes:", class_names)

    # Escolher aleatoriamente uma imagem e sua classe
    chosen_class = np.random.choice(class_names)
    image_files = os.listdir(os.path.join(file_teste, chosen_class))
    chosen_image = np.random.choice(image_files)
    image_path = os.path.join('sartaj_dataset/Testing', chosen_class, chosen_image)

    img = Image.open(image_path)

    width, height = img.size  # Obtém a largura e a altura da imagem

    print(f"Resolução da imagem: {width} x {height}")
    img2 = image.load_img(image_path, target_size=target_size, color_mode='grayscale')
    plt.imshow(img2, cmap='gray')
    plt.axis('off')
    plt.show()
    img = image.load_img(image_path, target_size=target_size, color_mode='grayscale')
    plt.imshow(img, cmap='gray')
    plt.axis('off')
    plt.show()

    # Predizer a classe da imagem
    img_array = image.img_to_array(img) / 255.0  # Pré-processamento
    img2 = image.img_to_array(img2) / 255.0
    img_array = np.expand_dims(img_array, axis=0)  # Simula um lote de tamanho 1
    img2 = np.expand_dims(img2, axis=0)  # Simula um lote de tamanho 1
    predictions = c.predict(img_array)
    print("Predição:", predictions)
    predicted_class_index = np.argmax(predictions[0])
    print("Classe prevista:", predicted_class_index)
    predicted_class = class_names[predicted_class_index]

    print("Classe real:", chosen_class)  # Adicione esta linha
    print("Classe prevista:", predicted_class)




    # Gerar e exibir variações da imagem
    image_gen = ImageDataGenerator(
    rotation_range=20,
    horizontal_flip=True,
    vertical_flip=True,
    zoom_range=0.2,
    fill_mode='constant',
    cval=0
    )
#fill_mode='constant' #constant - Preenchimento com preto - pixel mais próximo - nearest , reflect - refletindo a imagem - wrap embrulhando" a imagem
    img_array = img_array.reshape(1, target_size[0],target_size[1], 1)  # Remodela para a forma correta antes da expansão
    img2 = img2.reshape(1, target_size[0],target_size[1], 1)  # Remodela para a forma correta antes da expansão
    def plotImages(images_arr):
      fig, axes = plt.subplots(1, 10, figsize=(128,128))
      axes = axes.flatten()
      for img, ax in zip(images_arr, axes):
          ax.imshow(img.reshape(target_size[0],target_size[1]), cmap='gray')
          ax.axis('off')
      plt.tight_layout()
      plt.show()
    aut_gen= image_gen.flow(img_array)
    aut_images = [next(aut_gen)[0] for _ in range(10)]  # Gera 10 imagens aleatórias
    plotImages(aut_images)



